{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2348dca6-d164-4946-aa2b-10ee975f4d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "import holidays\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from pandas import DataFrame\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.neural_network import MLPRegressor as MLP\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7735520b-4432-4065-8dc8-3af97210046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed, change this value as you prefer\n",
    "np.random.seed(391)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed40fea-3aa0-4308-ae6a-688623e7ac9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd8ff427-2cdb-4c0e-9f35-a7a5e1f88a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_dir,\n",
    "            out_dir,\n",
    "            settings_dict={},\n",
    "            start_time=\"2016-01-01 00:00:00\",\n",
    "            end_time=\"2019-12-31 23:00:00\",\n",
    "            split_time=\"2018-12-31 23:00:00\",\n",
    "            batch_run=True,\n",
    "            target_ba_list=None,\n",
    "            generate_plots=True):\n",
    "    \"\"\"Convenience wrapper for the Process class which runs predictive models for each BA input CSV in the input\n",
    "    directory and creates a summary and comparative figures of R2 and MAPE per BA.\n",
    "\n",
    "    :param data_dir:                Full path to the directory containing the target CSV files\n",
    "    :type data_dir:                 str\n",
    "\n",
    "    :param out_dir:                 Full path to the directory where the outputs are to be written\n",
    "    :type out_dir:                  str\n",
    "\n",
    "    :param start_time:              Start-time for analysis, in YYY-MM-DD HH:MM:SS. Default: 2016-01-01 00:00:00\n",
    "    :type start_time:               str\n",
    "\n",
    "    :param end_time:                End time for analysis. Default: 2019-12-31 23:00:00\n",
    "    :type end_time:                 str\n",
    "\n",
    "    :param split_time:              Timestamp splitting train and test data. Default: 2018-12-31 23:00:00\n",
    "    :type split_time:               str\n",
    "\n",
    "    :param batch_run:               Indicating if we want to run the simulations for all BAs, or we handpick the BAs\n",
    "                                    If batch_run = True, the code will search for all BAs in 'dir'\n",
    "                                    If batch_run = False, we need to specify which BA to run\n",
    "    :type batch_run:                bool\n",
    "\n",
    "    :param target_ba_list:          A list of BA names to run if `batch_run` is False\n",
    "    :type target_ba_list:           list\n",
    "\n",
    "\n",
    "    :param generate_plots:          Choice to generate and save plots\n",
    "    :type generate_plots:           bool\n",
    "\n",
    "    :return:                        Data frame of BA, R2, MAPE statistics\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    proc = Process(\n",
    "        settings_dict=settings_dict,\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "        split_time=split_time,\n",
    "        batch_run=batch_run,\n",
    "        data_dir=data_dir,\n",
    "        out_dir=out_dir,\n",
    "        target_ba_list=target_ba_list,\n",
    "        generate_plots=generate_plots\n",
    "    )\n",
    "\n",
    "    return proc.summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532341c-a102-42ff-9c85-d2c8e48877e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_model(X: np.ndarray, Y: np.ndarray, X_e: np.ndarray):\n",
    "    \"\"\"Training and test data of a linear model. Can be used for either the main model or the residual model.\n",
    "\n",
    "    :param X:                       Training features\n",
    "    :type X:                        np.ndarray\n",
    "\n",
    "    :param Y:                       Training targets\n",
    "    :type Y:                        np.ndarray\n",
    "\n",
    "    :param X_e:                     Test features\n",
    "    :type X_e:                      np.ndarray\n",
    "\n",
    "    :return                         [0] y_p: predictions over test set\n",
    "                                    [1] reg.coef_: regression coefficients of a linear model\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # instantiate the linear model\n",
    "    linear_mod = LR()\n",
    "    \n",
    "    # fit the model\n",
    "    reg = linear_mod.fit(X, Y)\n",
    "\n",
    "    # get predictions using test features\n",
    "    y_p = reg.predict(X_e)\n",
    "\n",
    "    return y_p, reg.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c09bfd-e647-4db2-8a0c-31b49365659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_dict = {\n",
    "    \"mlp_hidden_layer_sizes\": 256,\n",
    "    \"mlp_max_iter\": 500,\n",
    "    \"mlp_validation_fraction\": 0.1,\n",
    "    \"mlp_linear_adjustment\": True,\n",
    "    \"data_column_rename_dict\": {\n",
    "            \"Adjusted_Demand_MWh\": \"Demand\",\n",
    "            \"Pop\": \"Population\",\n",
    "            \"T2\": \"Temperature\",\n",
    "            \"SWDOWN\": \"Shortwave_Radiation\",\n",
    "            \"GLW\": \"Longwave_Radiation\",\n",
    "            \"WSPD\": \"Wind_Speed\",\n",
    "            \"Q2\": \"Specific_Humidity\"\n",
    "    },\n",
    "    \"expected_datetime_columns\": [\"Day\", \"Month\", \"Year\", \"Hour\"],\n",
    "    \"hour_field_name\": \"Hour\",\n",
    "    \"month_field_name\": \"Month\",\n",
    "    \"x_variables\": [\"Hour\", \"Month\", \"Temperature\", \"Specific_Humidity\", \"Wind_Speed\", \"Longwave_Radiation\", \"Shortwave_Radiation\"],\n",
    "    \"add_dayofweek_xvar\": True,\n",
    "    \"y_variables\": [\"Demand\"],\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e93b969-c6bd-448d-9f70-e4a282e2af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \"\"\"Clean and format input data for use in predictive models.\n",
    "    \n",
    "    :param region:                  Indicating region / balancing authority we want to train and test on. \n",
    "                                    Must match with string in CSV files.\n",
    "    :type region:                   str \n",
    "    \n",
    "    :param data_dir:                Full path to the directory that houses the input CSV files.\n",
    "    :type data_dir:                 str \n",
    "    \n",
    "    :param settings_dict:           Dictionary of settings provided from either defaults or the user\n",
    "    :type settings_dict:            dict \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                region: str,\n",
    "                data_dir: str,\n",
    "                settings_dict: dict,\n",
    "                **kwargs):      \n",
    "        \n",
    "        self.region = region\n",
    "        self.data_dir = data_dir\n",
    "        self.start_time = start_time\n",
    "        self.end_time = end_time\n",
    "        \n",
    "        # get argument defaults or custom settings\n",
    "        self.expected_datetime_columns = settings_dict.get(\"expected_datetime_columns\")\n",
    "        self.data_column_rename_dict = settings_dict.get(\"data_column_rename_dict\")\n",
    "        self.x_variables = settings_dict.get(\"x_variables\")\n",
    "        self.y_variables = settings_dict.get(\"y_variables\")\n",
    "        self.mlp_linear_adjustment = settings_dict.get(\"mlp_linear_adjustment\")\n",
    "        self.hour_field_name = settings_dict.get(\"hour_field_name\")\n",
    "        self.month_field_name = settings_dict.get(\"month_field_name\")\n",
    "        self.verbose = settings_dict.get(\"verbose\")\n",
    "        \n",
    "        \n",
    "    def fetch_file(self):\n",
    "        \"\"\"Get the input file from the data directory matching the region name.\"\"\"\n",
    "        \n",
    "        file_pattern = os.path.join(self.data_dir, f\"{self.region}_*.csv\")\n",
    "        \n",
    "        # get file list from the data directory using the pattern\n",
    "        file_list = glob.glob(file_pattern)\n",
    "        \n",
    "        # raise error if no files are found\n",
    "        if len(file_list) == 0:\n",
    "            msg = f\"No data files were found for region '{self.region}' in directory '{self.data_dir}'.\n",
    "            raise FileNotFoundError(msg)\n",
    "            \n",
    "        # raise error if more than one file was found\n",
    "        if len(file_list) > 1:\n",
    "            msg = f\"More than one data files were found for region '{self.region}' in directory '{self.data_dir}'.\n",
    "            raise ValueError(msg)\n",
    "            \n",
    "        # log feedback to user if desired\n",
    "        if self.verbose:\n",
    "            print(f\"Processing file:  {file_list[0]}\")\n",
    "            \n",
    "        # return only the file path\n",
    "        return file_list[0]\n",
    "    \n",
    "    def format_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Read and format the input data file.  Filter data by user provided date range and sort in \n",
    "        ascending order by the timestamp.\n",
    "        \n",
    "        :return:                 Formatted data frame\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # get target file path\n",
    "        file_path = self.fetch_file()\n",
    "        \n",
    "        # read into a pandas data frame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # rename columns to default or user desired \n",
    "        df.rename(columns=self.data_column_rename_dict, inplace=True)\n",
    "        \n",
    "        # generate datetime timestamp field\n",
    "        df[\"Datetime\"] = pd.to_datetime(df[self.expected_datetime_columns])\n",
    "        \n",
    "        # filter by date range\n",
    "        df = df.loc[(df[\"Datetime\"] >= self.start_time) & (df[\"Datetime\"] <= self.end_time)]\n",
    "        \n",
    "        # sort values by timestamp\n",
    "        df.sort_values(by=[\"Datetime\"], inplace=True)\n",
    "        \n",
    "        # reset and drop index\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def apply_sine_for_linear_model(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Apply the sine function to the hour and month fields for use in a linear model as predictive variables.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # if a linear model will be ran and an hour field is present in the data frame apply the sine function\n",
    "        if (self.mlp_linear_adjustment) and (self.hour_field in df.columns):\n",
    "            df[self.hour_field_name] = np.sin(df[self.hour_field_name] * np.pi / 24)            \n",
    "\n",
    "        # if a linear model will be ran and an month field is present in the data frame apply the sine function\n",
    "        if (self.mlp_linear_adjustment) and (self.hour_field in df.columns):\n",
    "            df[self.month_field_name] = np.sin(df[self.month_field_name] * np.pi / 12)  \n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def apply_dayofweek(self: df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Add a field for weekday to the data frame.\"\"\"\n",
    "        \n",
    "        # create an array of day of the week values from the timestamp; 0 = Monday ... 6 = Sunday\n",
    "        df[\"Weekday\"] = df[\"Datetime\"].dt.dayofweek.values\n",
    "        \n",
    "        # adjust to specify weekdays as 1\n",
    "        df[\"Weekday\"] = np.where(df[\"Weekday\"] <= 4, 1, df[\"Weekday\"])\n",
    "        \n",
    "        # TODO:  start here\n",
    "        \n",
    "#         # specify weekday vdayofweek 0: monday, 6: sunday\n",
    "#         weekday = np.zeros_like(dayofweek)\n",
    "        \n",
    "#         weekday[dayofweek <= 4] = 1\n",
    "#         df[\"Weekday\"] = weekday\n",
    "\n",
    "#         # Create a day of week variable\n",
    "#         day_of_week = np.zeros((dayofweek.shape[0], 7))\n",
    "#         for d in range(7):\n",
    "#             tmp_val = np.zeros_like(dayofweek)\n",
    "#             tmp_val[dayofweek == d] = 1\n",
    "#             day_of_week[:, d] = tmp_val\n",
    "\n",
    "#         # concat day of week with df\n",
    "#         df_dayofweek = pd.DataFrame(day_of_week)\n",
    "\n",
    "#         # week list\n",
    "#         day_list = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n",
    "#         df_dayofweek.columns = day_list\n",
    "#         df = pd.concat((df, df_dayofweek), axis=1)\n",
    "\n",
    "#         # federal holidays added as a new feature\n",
    "#         df = self.remove_federal_holidays(df=df)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcd8b4bb-588b-4836-baa3-40f7b1eb4d07",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['hour'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-a85d0e57c144>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'day'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"28\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"29\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'month'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'year'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'2022'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2022'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'day'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'month'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hour'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/py3.9.4_ml/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3464\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/py3.9.4_ml/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[0;32m~/.pyenv/versions/py3.9.4_ml/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['hour'] not in index\""
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'day': [\"28\",\"29\"], 'month': [\"1\",\"1\"], 'year': ['2022', '2022']})\n",
    "\n",
    "pd.to_datetime(df[['day', 'month', 'year', 'hour']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be3c8365-de08-4866-949c-0deadd553a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>BB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  BB\n",
       "0  1   1\n",
       "1  2   2\n",
       "2  3   3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'c': \"ab\", \"b\": \"BB\"}, inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d7f763-5abf-42d9-ad2f-202af92e3ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45634a51-879c-4766-a689-ef94c3adaf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mlp_model(X: np.ndarray, \n",
    "                  Y: np.ndarray, \n",
    "                  X_e: np.ndarray, \n",
    "                  settings_dict: dict,\n",
    "                  **kwargs) -> np.ndarray:\n",
    "    \"\"\"Trains the MLP model. also calls the linear residual model to adjust for population correction.\n",
    "\n",
    "    :param X:                       Training features\n",
    "    :type X:                        np.ndarray\n",
    "\n",
    "    :param Y:                       Training targets\n",
    "    :type Y:                        np.ndarray\n",
    "\n",
    "    :param X_e:                     Test features\n",
    "    :type X_e:                      np.ndarray\n",
    "    \n",
    "    :param settings_dict:           Dictionary of settings provided from either defaults or the user\n",
    "    :type settings_dict:            dict \n",
    "\n",
    "    :return:                        y_p: np.ndarray -> predictions over test set\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # get argument defaults or custom settings\n",
    "    mlp_hidden_layer_sizes = settings_dict.get(\"mlp_hidden_layer_sizes\")\n",
    "    mlp_max_iter = settings_dict.get(\"mlp_max_iter\")\n",
    "    mlp_validation_fraction = settings_dict.get(\"mlp_validation_fraction\")\n",
    "    mlp_linear_adjustment = settings_dict.get(\"mlp_linear_adjustment\")\n",
    "\n",
    "    # instantiate the MLP model\n",
    "    mlp = MLP(hidden_layer_sizes=mlp_hidden_layer_sizes, \n",
    "              max_iter=mlp_max_iter, \n",
    "              validation_fraction=mlp_validation_fraction)\n",
    "\n",
    "    # fit the model to data matrix X (training features) and target Y (training targets)\n",
    "    mlp.fit(X, Y)\n",
    "\n",
    "    # predict using the multi-layer perceptron model using the test features\n",
    "    y_p = mlp.predict(X_e)\n",
    "    \n",
    "    # if the user desired, adjust the prediction using a linear residual model\n",
    "    if mlp_linear_adjustment:\n",
    "        \n",
    "        # predict on training features\n",
    "        y_tmp = mlp.predict(X)\n",
    "        \n",
    "        # compute the residuals in the training data\n",
    "        epsilon = Y - y_tmp\n",
    "        \n",
    "        # prepare data for the residual model\n",
    "        # TODO: produce Xres_t, Xres_e\n",
    "\n",
    "        # train the linear model to find residuals\n",
    "        epsilon_e, regression_coeff = run_linear_model(X=Xres_t , Y=epsilon, X_e=Xres_e)\n",
    "        \n",
    "        # apply the adjustment\n",
    "        y_p += epsilon_e\n",
    "        \n",
    "    return y_p\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d3e8628-4ed7-46a1-bb04-8b7b2428a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x, y, **kwargs):\n",
    "    \n",
    "    print(x, y, kwargs)\n",
    "    \n",
    "    settings_dict = kwargs.get('settings_dict')\n",
    "    \n",
    "    print(settings_dict.get('hidden_layer_sizes'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2710814d-ee21-494f-9a8e-2775b6533f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 {'settings_dict': {'hidden_layer_sizes': 256, 'max_iter': 500}}\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "test(1, 2, settings_dict={'hidden_layer_sizes': 256, 'max_iter': 500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1474c15b-405b-46ad-9b22-89fb346773b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.4_ml",
   "language": "python",
   "name": "py3.9.4_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
